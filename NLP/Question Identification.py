# -*- coding: utf-8 -*-
"""DEVANSI_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16t-Hb_0QwLsYJ1O08RETas6RwbEsocX4
"""

# Install required packages
!pip install gensim nltk spacy pandas scikit-learn matplotlib seaborn
!python -m spacy download en_core_web_sm

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import string
import re
import spacy
from gensim.models import Word2Vec
from scipy.sparse import hstack

# Download NLTK resources
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('omw-1.4')
nltk.download('averaged_perceptron_tagger')

# Load spaCy model
nlp = spacy.load('en_core_web_sm')

# Load dataset (update path as needed)
try:
    df = pd.read_csv('/media/Data Set __1748351159-5ea65d4bfbba7875acb26a15.csv')

    # Clean column names and handle missing columns
    df.columns = df.columns.str.strip().str.lower()
    if 'label' in df.columns and 'is_question' not in df.columns:
        df['is_question'] = df['label'].map({'question': 1, 'sentence': 0, 'Question': 1, 'Sentence': 0}).astype(int)

    print("Dataset loaded successfully. Shape:", df.shape)
except Exception as e:
    print("Error loading dataset:", str(e))
    raise

## Text Preprocessing
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = re.sub(r'\d+', '', text)
    return ' '.join(text.split())

def lemmatize_text(text):
    if not isinstance(text, str):
        return ""
    try:
        words = word_tokenize(text)
        lemmatizer = WordNetLemmatizer()
        stop_words = set(stopwords.words('english'))
        return ' '.join([lemmatizer.lemmatize(word) for word in words if word not in stop_words])
    except Exception as e:
        print(f"Lemmatization error: {str(e)}")
        return text

def get_pos_tags(text):
    if not isinstance(text, str):
        return ""
    try:
        doc = nlp(text)
        return ' '.join([token.pos_ for token in doc])
    except Exception as e:
        print(f"POS tagging error: {str(e)}")
        return ""

# Apply preprocessing
df['cleaned_text'] = df['text'].apply(clean_text)
df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)
df['pos_tags'] = df['cleaned_text'].apply(get_pos_tags)v

## Feature Engineering
# Split data
if 'is_question' not in df.columns:
    raise KeyError("Target column 'is_question' not found in dataset")

X = df['lemmatized_text']
y = df['is_question']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 1. TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# 2. POS Tag Features
pos_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=1000)
X_train_pos = pos_vectorizer.fit_transform(df.loc[X_train.index, 'pos_tags'])
X_test_pos = pos_vectorizer.transform(df.loc[X_test.index, 'pos_tags'])

# 3. Word2Vec Embeddings
sentences = [text.split() for text in df['lemmatized_text']]
word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

def average_word_vectors(words, model, vocabulary, num_features):
    feature_vector = np.zeros((num_features,), dtype="float64")
    n_words = 0

    for word in words:
        if word in vocabulary:
            n_words += 1
            feature_vector = np.add(feature_vector, model.wv[word])

    if n_words > 0:
        feature_vector = np.divide(feature_vector, n_words)

    return feature_vector

vocabulary = set(word2vec_model.wv.index_to_key)
X_train_word2vec = np.array([average_word_vectors(text.split(), word2vec_model, vocabulary, 100) for text in X_train])
X_test_word2vec = np.array([average_word_vectors(text.split(), word2vec_model, vocabulary, 100) for text in X_test])

# Combine features
X_train_combined = hstack([X_train_tfidf, X_train_pos])
X_test_combined = hstack([X_test_tfidf, X_test_pos])

## Model Training and Evaluation
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='linear', probability=True, random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42)
}

plt.figure(figsize=(10, 8))
roc_curves = {}

for model_name, model in models.items():
    try:
        print(f"\nTraining {model_name}...")

        # Select appropriate features
        if model_name == 'Naive Bayes':
            X_tr, X_te = X_train_tfidf, X_test_tfidf  # Naive Bayes works best with TF-IDF
        else:
            X_tr, X_te = X_train_combined, X_test_combined

        model.fit(X_tr, y_train)
        y_pred_prob = model.predict_proba(X_te)[:, 1]

        # Calculate metrics
        fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
        roc_auc = auc(fpr, tpr)
        roc_curves[model_name] = (fpr, tpr, roc_auc)

        # Plot ROC
        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')

        # Print classification report
        y_pred = model.predict(X_te)
        print(classification_report(y_test, y_pred))

    except Exception as e:
        print(f"Error with {model_name}: {str(e)}")

# Final ROC plot
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Question Detection Models')
plt.legend(loc="lower right")
plt.show()

## Hyperparameter Tuning for Best Model
print("\nPerforming hyperparameter tuning...")
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('clf', LogisticRegression())
])

param_grid = {
    'tfidf__ngram_range': [(1, 1), (1, 2)],
    'tfidf__max_features': [5000, 10000],
    'clf__C': [0.1, 1, 10],
    'clf__penalty': ['l1', 'l2'],
    'clf__solver': ['liblinear']
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=1)
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

# Evaluate best model
y_pred_prob = best_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Best Model')
plt.legend(loc="lower right")
plt.show()

print("\nFinal Evaluation:")
y_pred = best_model.predict(X_test)
print(classification_report(y_test, y_pred))